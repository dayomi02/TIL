# RAG

Retrieval-Augmented Generation (검색 증강 생성)

대규모 언어 모델의 출력을 최적화하여 응답을 생성하기 전에 학습 데이터 소스 외부의 신뢰할 수 있는 지식 베이스를 참조하도록 하는 프로세스이다. LLM(대규모 언어 모델)은 방대한 양의 데이터를 기반으로 학습되며 수십억 개의 매개변수를 사용하여 질문에 대한 답변, 언어 변역, 문장 완성과 같은 작업에 대한 독창적인 결과를 생성한다. 

RAG는 이미 강력한 LLM의 기능을 특정 도메인이나 조직의 내부 지식 기반으로 확장하므로 모델을  다시 교육할 필요가 없다. 즉 RAG는 LLM 결과를 개선하여 다양한 상황에서 관련성, 정확성 및 유용성을 유지하기 위한 비용 효율적인 접근 방식이다.

LLM의 문제점은 다음과 같다.

- 답변이 없을 때 허위 정보를 제공한다.
- 사용자가 구체적이고 최신의 응답을 기대할 때 오래되었거나 일반적인 정보를 제공한다.
- 신뢰할 수 없는 출처로부터 응답을 생성한다.
- 용어 혼동으로 인해 응답이 정확하지 않다. 다양한 훈련 소스가 동일한 용어를 사용하려 서로 다른 내용을 설명한다.

LLM은 최신 정보를 학습하지 않으면 최신 정보에 대한 응답을 할 수 없다.

RAG는 이러한 문제 중 일부를 해결하기 위한 한 가지 접근 방식이다. LLM을 리디렉션(다시 지시하는 것)하여 신뢰할 수 있는 사전 결정된 지식 출처에서 관련 정보를 검색한다.
조직은 생성된 텍스트 출력을 더 잘 제어할 수 있으며 사용자는 LLM이 응답을 생성하는 방식에 대한 통찰력을 얻을 수 있다.

- Fine-Tuning : 새로운 지식에 관한 텍스트 데이터 소스를 이용해서 LLM 파라미터를 Fine-Tuning한다.

### RAG 이점

- **비용 효율적인 구현**
    
    RAG는 LLM에 새 데이터를 도입하기 위한 보다 비용 효율적인 접근 방식이다. 이를 통해 생성형 인공 지능 기술을 보다 폭넓게 접근하고 사용할 수 있다.
    
- **최신 정보**
    
    RAG를 사용하여 생성 모델에 최신 연구 통계 또는 뉴스를 제공할 수 있다. 라이브 소셜 미디어 피드, 뉴스 사이트 또는 기타 자주 업데이트 되는 정보 소스에 직접 연결할 수 있다. 그러면 LLM은 사용자에게 최신 정보를 제공할 수 있다.
    
- **사용자 신뢰 강화**
    
    출력에는 소스에 대한 인용 또는 참조가 포함될 수 있다. 사용자는 추가 설명이나 세부 정보가 필요한 경우 소스 문서를 직접 찾아볼 수도 있다. 이를 통해 생성형 AI 솔루션에 대한 신뢰와 확신을 높일 수 있다.
    
- **개발자 제어 강화**

### RAG 동작?

RAG가 없는 경우 LLM은 사용자 입력을 받아 훈련한 정보 도는 이미 알고 있는 정보를 기반으로 응답을 생성한다. 
RAG에는 사용자 입력을 활용하여 먼저 새 데이터 소스에서 정보를 가져오는 정보 검색 구성 요소가 도입되었다. 사용자 쿼리와 관련 정보가 모두 LLM에 제공된다. 따라서 LLM은 새로운 지식과 학습 데이터를 사용하려 더 나은 응답을 생성한다.

- **외부 데이터 생성**
    - *외부 데이터* : LLM의 원래 학습 데이터 세트 외부에 있는 새 데이터. API, 데이터베이스 또는 문서 리포지토리와 같은 여러 데이터 소스에서 가져올 수 있음.
    - *임베딩 언어 모델* : AI 기법. 데이터를 수치로 변환하고 벡터 데이터베이스에 저장.
    
    외부 데이터를 임베딩 언어 모델을 사용해서 벡터 데이터베이스에 저장한다. 이 프로세스는 생성형 AI 모델이 이해할 수 있는 지식 라이브러리를 생성하는 것이다.
    
- **관련 정보 검색**
    
    사용자 쿼리는 벡터 표현으로 변환 → 벡터 데이터베이스와 매칭 
    
- **LLM 프롬프트 확장**
    
    RAG 모델은 검색된 관련 데이터를 컨텍스트에 추가하려 사용자 입력(또는 프롬프트)를 보강한다. 대규모 언어 모델이 사용자 쿼리에 대한 정확란 답변을 생성할 수 있다.
    
- **외부 데이터 업데이트**
    
    검색을 위해 퇴신 정보를 유지하기 위해 문서를 비동기적으로 업데이트하고 문서의 임베딩 표현을 업데이터한다. 자동화된 실시간 프로세스 또는 주기적 배치 처리를 통해 이 작업을 수행할 수 있다.
    


### RAG와 시맨틱 검색의 차이점

시맨틱 검색은 방대한 외부 지식 소스를 LLM 애플리케이션에 추가하려는 RAG 결과를 향상시킨다. 컨택스트 검색은 대규모로 실행하기 어려우며 결과적으로 생성 출력 품질이 떨어진다.

시맨틱 검색 기술을 서로 다른 정보의 대규모 데이터베이스를 스캔하고 데이터를 더 정확하게 검색할 수 있다.

RAG의 기존 또는 키워드 검색 솔루션은 지식 집약적 작업에 대해 제한된 결과를 제공한다. 또는 개발자는 수동으로 데이터를 준비할 때 워드 임베딩, 문서 청킹 및 기터 복잡한 문제를 해결해야 한다. 반대로 시맨틱 검색 기술은 지식 기반 준비의 모든 작업을 수행하므로 개발자는 그럴 필요가 없다.



[RAG란? - 검색 증강 생성 설명 - AWS (amazon.com)](https://aws.amazon.com/ko/what-is/retrieval-augmented-generation/)
[검색 증강 생성(RAG)이란? | 포괄적인 RAG 안내서](https://www.elastic.co/kr/what-is/retrieval-augmented-generation)
